---
title: "week7_recap"
author: "Daniel Trielli"
date: "2023-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Turn off scientific notation
options(scipen=999)
```

## Loading the packages

Run the codeblock below to load the packages we will need for this recap

```{r}
library(tidyverse)
library(lubridate)
library(janitor)
```

## Load Data

Run the codeblock below to load the data.

```{r}
earthquakes <- read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv')

#Setting time column as datetime
earthquakes <- earthquakes |> mutate(time = as_datetime(time))
```

#### Answer the questions below

Most questions have a code block and a space for an answer below. Write the code you think is necessary and, in the answer space, write out what you did and what was the result.

------------------------------------------------------------------------

#### **Q1** Look at the earthquakes dataset. Finish the sentence below as if you were explaining the data to someone who had not seen it before but needs to know about it.

**A1:** This dataset contains a list of all earthquakes and similar events across the world standardized to GMT and where they happen (longitude and latitude).

```{r}
group_by(earthquakes)


```

------------------------------------------------------------------------

#### **Q2** How many records there are there in this dataset? What do they mean and what useful information we can gather from it, looking at the columns?

**A2:** There are 9774 rows in this dataset. Each row represents either an earthquake, an explosion, an ice quake, other event, quarry blast and gives you information on where and when they occured, the depth at which it occurred, and the earthquake magnitude..

```{r}
earthquakes |> 
  summarize(count = n())
earthquakes |> 
  group_by(type) |> 
  summarize(count = n())
```

------------------------------------------------------------------------

#### **Q3** How do I reorganize this data to see the ones that are the deepest first? What is the depth that shows up for the deepest one, and its magnitude?

**A3:** To reorganize the data so you can see the deepest first, you write the following code:

```{r}
earthquakes |> 
  group_by(depth) |>  
  arrange(desc(depth))

```

The deepest depth an earthquake occured is 669.982 km with a 4.2 magnitude on the Richter scale.

------------------------------------------------------------------------

#### **Q4** I just want to see the earthquakes with a magnitude larger than 6. How do I do that? And how many are there that fit this criteria?

```{r}
earthquakes_larger_than_6 <- earthquakes |> 
  filter(mag>6) 
 
earthquakes_larger_than_6 |> 
  summarize(count = n())
```

**A4:** There are 13 earthquakes with a magnitude greater than 6.

------------------------------------------------------------------------

#### **Q5** What about if I want to see earthquakes that have both a magnitude larger than 6 and a depth smaller than 20? How many are there in the data set that fit [both]{.underline} these criteria?

```{r}
earthquakes |> 
  filter(mag>6) |> 
  filter(depth<20) |> 
  summarize(count = n())
```

**A5:** 6 earthquakes have a magnitutde greater than 6 but with a depth less than 20 km.

------------------------------------------------------------------------

#### **Q6** What about if I want to see earthquakes that either have a magnitude larger than 6 OR a depth smaller than 20? How many are there in the data set that fit [either]{.underline} these criteria?

```{r}
earthquakes |> 
  filter(mag>6 | depth<20) |> 
  summarize(count = n())
```

**A6:** 7446 earthquakes have a magnitude larger than 6 but a depth smaller than 20 km.

------------------------------------------------------------------------

#### **Q7** I'm interested in finding earthquakes that took place in Alaska. Which column should I look at? How do I use it to find all the earthquakes in Alaska? How many earthquakes took place there?

**A7:** You would look at the column "place." You'd use a str_detect and search for "Alaska."

```{r}
earthquakes |> 
   filter(str_detect(place, "alaska") | str_detect(place, "Alaska"))
```

------------------------------------------------------------------------

#### **Q8** I notice that there is a column called 'type', that seems to have different kinds of tremors. What is the best way to find what are all the possible types of tremors, and counting how many of each there are in this data set? What are the first two most common types of tremors in this data set?

```{r}
earthquakes %>% 
  group_by(type) %>% 
  summarize(count = n())
```

**A8:** The first two most common are earthquake, then explosion.

------------------------------------------------------------------------

#### **Q9** What is the average depth of the earthquake type in this data set? Is there anything that seems unusual or surprising in this finding?

```{r}
summary_earthquakes <- earthquakes |> 
  filter(str_detect(type, "earthquake")) 

summary_earthquakes 

summary_earthquakes |> 
  summary(summary_earthquakes)
```

**A9:** 25.24 is the average depth. It looks like there's outlier earthquakes way deep down which is pulling the mean down, since the median is around 6. That's really interesting to me.

------------------------------------------------------------------------

#### **Q10** I'm interested, in the future, to see the hours in which earthquakes happen. How can I extract the hour from the time column?

```{r}
serious_earthquakes <- earthquakes |> 
  mutate(hour=hour(time))

serious_earthquakes
```

**A10:** See above. The "hour" column shows just the hour.

------------------------------------------------------------------------

#### **Q11** I want to make a note of all the records in this data set that I consider serious. For my purposes, I'm thinking that all tremors that have a magnitude that is larger than 3 are serious. How do I automatically create a new column showing whether an earthquake is serious or not?

```{r}
## earthquakes |> 
 ## filter(mag>3) |> 
 ## mutate(serious_earthquakes="Serious")

serious_earthquakes <- serious_earthquakes |> 
  mutate(
    state = case_when(
        mag>3 ~ "serious",
        .default = "not serious")
      )
    ## makes a NEW column with whether it's serious or not
  
  serious_earthquakes

```

**A11:**

------------------------------------------------------------------------

#### **Q12** I have no idea how earthquakes work and I'm interested in seeing if there is a particular time of day in which serious earthquakes happen. How can I see that condensed in a table with all the hours in a day and all the serious earthquakes in each hour? What is the hour with fewer serious earthquakes and the one with the most serious earthquakes?

```{r}
only_serious_earthquakes <- serious_earthquakes |>
  filter(!str_detect(state, "not")) |> 
  select (hour, state)

only_serious_earthquakes
```

**A12**: At first, I tried putting in "serious" as the condition I wanted. Here's what that code looked like:

```{r}
only_serious_earthquakes <- serious_earthquakes |>
  filter(str_detect(state, "serious"))

only_serious_earthquakes
```

But I realized, upon looking at the data, that it includes both "not serious" and "serious" -- the literal opposite of what I want. I read back through my class notebook and found the != character. I reasoned that I could use it to filter out the "not," which is what separates the "not serious" from the "serious". Here's what my code looked like:

```{r}
only_serious_earthquakes <- serious_earthquakes |>
  filter(str_detect(state !="not")) 
```

When you run that, you'll see that it returns an error saying: ""Error in filter(serious_earthquakes, str_detect(state !="not")) : Caused by error in \`str_detect()\`: ! argument "pattern" is missing, with no default"

This might as well have been written in Chinese. I asked my friend ChatGPT what the hell was wrong with my code and it, helpfully told me that my code was wrong and corrected the place of the exclamation mark so the code looked like this:

```{r}
only_serious_earthquakes <- serious_earthquakes |>
  filter(!str_detect(state, "not")) |> 
  select (hour, state)

only_serious_earthquakes
```

Out of curiosity, I asked ChatGPT how I would have gotten R to show me only cells containing exactly "serious" (i.e. **not** "not serious"). Chat GPT told me that I would have to use the == like so:

```{r}
only_serious_earthquakes <- serious_earthquakes |>
  filter(state == "serious")

```

------------------------------------------------------------------------

#### **Q13** What's another question you are interested in and how would you ask it in R?

**A13:** I'd like to know on average during what hour most earthquakes happen in California. Here's how I'd ask it.

Before that, though - I want to figure out what the dataset calls California. Here's the code I got from ChatGPT.

```{r}
unique_places <- earthquakes |> 
  distinct(place)

```

Looks like it only uses "California" and "CA" to refer to California. Just to be sure, I've included an entry for "cali." Instead of writing out "California," I chose to tell R to look for any words that start with "Cali" or "cali." This way I hope I can capture typos.

```{r}
california_earthquakes <- earthquakes |> 
  filter(str_detect(place, "(^Cali|^cali|CA)") & !str_detect(place, "(Nevada|nevada|Arizona|arizona|Oregon|oregon)")) 

```

Let's stop right there - that's a lot of things happening. As explained above, I'm trying to make sure all references to California get included. But I noticed there are several entries that read "California-NevadaÂ border region." That's why I filtered out the Nevada results with the ! expression. But upon further reflection, I realized that California borders more than just Nevada, it also borders Arizona and Oregon.

```{r}
## searching for everything that IS "CA" or starts with "Cali" (upper or lowercase) AND is not "Nevada"
## arguably, I should give Nevada the same treatement I gave California, telling R that I don't want it to spit back results that start with "Nev" but I'm pretty confident "Nevada" is going to be spelled right. Honestly, same for California, but - what if? 
## I did not give Nevada the same treatment that I gave California's abbreviation, CA, because I couldn't find any time that Nevada was abbreviated in conjunction with a reference to California. Instead, everything that includes Nevada and California says "Nevada-California border"


california_earthquakes <- earthquakes |> 
  filter(str_detect(place, "(^Cali|^cali|CA)") & !str_detect(place, "(Nevada|nevada|Arizona|arizona|Oregon|oregon)")) |> 
  mutate(hour = hour(time)) |> 
  summarize(mean_hour = round(mean(hour, na.rm = TRUE))) |> 
  select(mean_hour)

## filter(str_detect(place, "alaska") | str_detect(place, "Alaska"))

california_earthquakes

```

So, on average, most earthquakes in California occur at 12 PM. Interesting.
